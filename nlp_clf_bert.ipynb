{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cac8c137-f7d3-40c9-90b1-15132e165ce8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "import torch\n",
    "import transformers\n",
    "from collections import Counter\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, pipeline, BitsAndBytesConfig\n",
    "\n",
    "import accelerate\n",
    "from accelerate import Accelerator\n",
    "\n",
    "import langchain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9143a015-b723-41a1-ae8a-8364cfd24af6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import T5Tokenizer\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from torch.utils.data import RandomSampler, SequentialSampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "93dd0543-a7b8-45d5-9ef2-955285ae780a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\dohyeong\\anaconda3\\lib\\site-packages\\awq\\modules\\linear\\exllama.py:12: UserWarning: AutoAWQ could not load ExLlama kernels extension. Details: DLL load failed while importing exl_ext: 지정된 프로시저를 찾을 수 없습니다.\n",
      "  warnings.warn(f\"AutoAWQ could not load ExLlama kernels extension. Details: {ex}\")\n",
      "c:\\users\\dohyeong\\anaconda3\\lib\\site-packages\\awq\\modules\\linear\\exllamav2.py:13: UserWarning: AutoAWQ could not load ExLlamaV2 kernels extension. Details: DLL load failed while importing exlv2_ext: 지정된 프로시저를 찾을 수 없습니다.\n",
      "  warnings.warn(f\"AutoAWQ could not load ExLlamaV2 kernels extension. Details: {ex}\")\n",
      "c:\\users\\dohyeong\\anaconda3\\lib\\site-packages\\awq\\modules\\linear\\gemm.py:14: UserWarning: AutoAWQ could not load GEMM kernels extension. Details: DLL load failed while importing awq_ext: 지정된 프로시저를 찾을 수 없습니다.\n",
      "  warnings.warn(f\"AutoAWQ could not load GEMM kernels extension. Details: {ex}\")\n",
      "c:\\users\\dohyeong\\anaconda3\\lib\\site-packages\\awq\\modules\\linear\\gemv.py:11: UserWarning: AutoAWQ could not load GEMV kernels extension. Details: DLL load failed while importing awq_ext: 지정된 프로시저를 찾을 수 없습니다.\n",
      "  warnings.warn(f\"AutoAWQ could not load GEMV kernels extension. Details: {ex}\")\n",
      "c:\\users\\dohyeong\\anaconda3\\lib\\site-packages\\awq\\modules\\linear\\gemv_fast.py:10: UserWarning: AutoAWQ could not load GEMVFast kernels extension. Details: DLL load failed while importing awq_v2_ext: 지정된 프로시저를 찾을 수 없습니다.\n",
      "  warnings.warn(f\"AutoAWQ could not load GEMVFast kernels extension. Details: {ex}\")\n"
     ]
    }
   ],
   "source": [
    "from langchain.llms import HuggingFacePipeline\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain.schema import Document\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter, MarkdownTextSplitter, MarkdownHeaderTextSplitter\n",
    "from langchain.prompts import PromptTemplate, ChatPromptTemplate\n",
    "from langchain.schema.runnable import RunnablePassthrough\n",
    "from langchain.schema.output_parser import StrOutputParser\n",
    "from langchain_teddynote.retrievers import KiwiBM25Retriever\n",
    "from langchain.retrievers import EnsembleRetriever, MultiQueryRetriever\n",
    "from langchain.document_loaders import PDFPlumberLoader, PyMuPDFLoader, PyPDFLoader, UnstructuredPDFLoader\n",
    "\n",
    "import peft\n",
    "from peft import PeftModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "04cec5d5-a02b-4d9d-910b-c00f55638a7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datasets\n",
    "from datasets import Dataset\n",
    "from transformers import Trainer, TrainingArguments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "14f87933-7f1e-404c-8feb-5e7b613ce436",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import T5ForTokenClassification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fe26060f-4b45-47ce-9ca4-5ac8e4f7163e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ddd1583d-b1a4-4246-9598-186fb51d9c7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7df70a97-a2ed-4103-9edb-07cb3e0990c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of T5ForTokenClassification were not initialized from the model checkpoint at t5-small and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model = T5ForTokenClassification.from_pretrained(\n",
    "    pretrained_model_name_or_path = 't5-small'\n",
    ").to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "333f8085-597e-44b7-afbe-5f72a8da1444",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of T5ForTokenClassification were not initialized from the model checkpoint at t5-small and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "epochs = 5\n",
    "batch_size = 32\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "tokenizer = T5ForTokenClassification.from_pretrained(\n",
    "    pretrained_model_name_or_path='t5-small',\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bf23384e-6f00-49bd-a04a-f8d1e2f1321d",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "27cf286f-bf3d-4618-a7a9-90106de2a7a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = data['first_party'] + data['second_party'] + data['facts'] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "08d236a3-8b78-4515-9df8-d9b3dc98d9a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(df)\n",
    "df = pd.concat([df, data['first_party_winner']], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6dadd154-60d1-45c2-83e7-9eff08df4e20",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns = ['informations', 'label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9c357a94-0d38-4b70-b46f-8f1898ac3836",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_accuracy(preds, labels):\n",
    "    pred_flat = np.argmax(preds.cpu().numpy(), axis=1).flatten()\n",
    "    labels_flat = labels.flatten()\n",
    "    return np.sum(pred_flat == labels_flat) / len(labels_flat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7e88cc7d-e1d9-4580-a278-87c234900482",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_dataset(data, tokenizer, device):\n",
    "    tokenized = tokenizer(\n",
    "        text = data.informations.tolist(),\n",
    "        padding= 'longest',\n",
    "        truncation = True,\n",
    "        return_tensors = 'pt'\n",
    "    )\n",
    "    input_ids = tokenized['input_ids'].to(device)\n",
    "    attention_mask = tokenized['attention_mask'].to(device)\n",
    "    labels = torch.tensor(data.label.values, dtype=torch.long).to(device)\n",
    "    return TensorDataset(input_ids, attention_mask, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "15ff27e6-817a-4c8a-8a0d-3779fc8f40da",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dataloader(dataset, sampler, batch_size):\n",
    "    data_sampler = sampler(dataset)\n",
    "    dataloader = DataLoader(dataset, sampler = data_sampler, batch_size = batch_size)\n",
    "    return dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "75174e76-fb71-4e75-803c-f9612ce8f264",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import BertTokenizer\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from torch.utils.data import RandomSampler, SequentialSampler\n",
    "from torch import optim\n",
    "from transformers import BertForSequenceClassification\n",
    "from torch import nn\n",
    "import math\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.nn.utils.rnn import pad_sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e185b2cd-f998-4e47-b6f4-9a682d079cf3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\dohyeong\\anaconda3\\lib\\site-packages\\transformers\\tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "epochs = 5\n",
    "batch_size = 8\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "tokenizer = BertTokenizer.from_pretrained(\n",
    "    pretrained_model_name_or_path='bert-base-multilingual-cased',\n",
    "    do_lower_case = False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "68e1d4a1-6cdc-4f3d-8f26-3134a9db61b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\dohyeong\\anaconda3\\lib\\site-packages\\numpy\\core\\fromnumeric.py:59: FutureWarning: 'DataFrame.swapaxes' is deprecated and will be removed in a future version. Please use 'DataFrame.transpose' instead.\n",
      "  return bound(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "train, valid, test = np.split(\n",
    "    df.sample(frac=1, random_state=42), [int(0.6*len(df)), int(0.8*len(df))]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "cb81e8af-d0f7-4bbf-8287-ccb994160597",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>informations</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1753</th>\n",
       "      <td>Gerald E. MansellGaye M. Mansell Major Gerald ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>259</th>\n",
       "      <td>FreedmanMarylandMaryland required that all fil...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2072</th>\n",
       "      <td>BMW of North America, Inc.GoreAfter purchasing...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1000</th>\n",
       "      <td>MarylandWirtzThe Fair Labor Standards Act of 1...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>Randall D. WhiteState of IllinoisDuring Randal...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1402</th>\n",
       "      <td>Zenith Radio CorporationHazeltine Research, In...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018</th>\n",
       "      <td>BlessingFreestoneCathy Freestone and four othe...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2240</th>\n",
       "      <td>United States Trust Company of New YorkNew Jer...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1964</th>\n",
       "      <td>Commissioner of Internal Revenue, Philip D. Fa...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>724</th>\n",
       "      <td>Travelers Casualty &amp; Surety Company of America...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1486 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           informations  label\n",
       "1753  Gerald E. MansellGaye M. Mansell Major Gerald ...      1\n",
       "259   FreedmanMarylandMaryland required that all fil...      1\n",
       "2072  BMW of North America, Inc.GoreAfter purchasing...      1\n",
       "1000  MarylandWirtzThe Fair Labor Standards Act of 1...      0\n",
       "56    Randall D. WhiteState of IllinoisDuring Randal...      0\n",
       "...                                                 ...    ...\n",
       "1402  Zenith Radio CorporationHazeltine Research, In...      1\n",
       "2018  BlessingFreestoneCathy Freestone and four othe...      1\n",
       "2240  United States Trust Company of New YorkNew Jer...      1\n",
       "1964  Commissioner of Internal Revenue, Philip D. Fa...      0\n",
       "724   Travelers Casualty & Surety Company of America...      1\n",
       "\n",
       "[1486 rows x 2 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3c1609dc-b6f3-4297-93ce-fbf88a444218",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>informations</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1314</th>\n",
       "      <td>Tim Shoop, WardenDanny HillIn 1986, Danny Hill...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1736</th>\n",
       "      <td>Gloria Gail Kurns, Executrix of the Estate of ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>269</th>\n",
       "      <td>United StatesAnthony James KebodeauxAnthony Ke...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1749</th>\n",
       "      <td>Seila Law LLCConsumer Financial Protection Bur...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2044</th>\n",
       "      <td>United States of AmericaRene Sanchez-Gomez, et...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1253</th>\n",
       "      <td>Ivan EberhartUnited StatesIvan Eberhart was co...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1276</th>\n",
       "      <td>Pearly L. WilsonRichard Seiter et al.While det...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>912</th>\n",
       "      <td>Steven A. LevinUnited States, et al.On March 1...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>491</th>\n",
       "      <td>American Tradition Partnership, Inc.Steve Bull...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>953</th>\n",
       "      <td>Festo CorporationShoketsu Kinzoku Kogyo Kabush...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>496 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           informations  label\n",
       "1314  Tim Shoop, WardenDanny HillIn 1986, Danny Hill...      1\n",
       "1736  Gloria Gail Kurns, Executrix of the Estate of ...      0\n",
       "269   United StatesAnthony James KebodeauxAnthony Ke...      1\n",
       "1749  Seila Law LLCConsumer Financial Protection Bur...      1\n",
       "2044  United States of AmericaRene Sanchez-Gomez, et...      1\n",
       "...                                                 ...    ...\n",
       "1253  Ivan EberhartUnited StatesIvan Eberhart was co...      1\n",
       "1276  Pearly L. WilsonRichard Seiter et al.While det...      0\n",
       "912   Steven A. LevinUnited States, et al.On March 1...      1\n",
       "491   American Tradition Partnership, Inc.Steve Bull...      1\n",
       "953   Festo CorporationShoketsu Kinzoku Kogyo Kabush...      0\n",
       "\n",
       "[496 rows x 2 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9bda2e53-b5bb-4d5b-bece-2809d12e95eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = make_dataset(train, tokenizer, device)\n",
    "train_dataloader = get_dataloader(train_dataset, RandomSampler, batch_size)\n",
    "\n",
    "valid_dataset = make_dataset(valid, tokenizer, device)\n",
    "valid_dataloader = get_dataloader(valid_dataset, RandomSampler, batch_size)\n",
    "\n",
    "test_dataset = make_dataset(test, tokenizer, device)\n",
    "test_dataloader = get_dataloader(test_dataset, RandomSampler, batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1ada46b1-e973-46df-8e6c-0e469584f508",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-multilingual-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model = BertForSequenceClassification.from_pretrained(\n",
    "    pretrained_model_name_or_path='bert-base-multilingual-cased',\n",
    "    num_labels = 2\n",
    ").to(device)\n",
    "optimizer = optim.AdamW(model.parameters(), lr=1e-5, eps=1e-8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "92d8d0e0-da30-4109-b057-149ccfcd6121",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, optimizer, dataloader):\n",
    "    model.train()\n",
    "    train_loss = 0.0\n",
    "    \n",
    "    for input_ids, attention_mask, labels in dataloader:\n",
    "        outputs = model(\n",
    "            input_ids = input_ids,\n",
    "            attention_mask = attention_mask,\n",
    "            labels = labels\n",
    "        )\n",
    "        \n",
    "        loss = outputs.loss\n",
    "        train_loss += loss.item()\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "    train_loss = train_loss / len(dataloader)\n",
    "    return train_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "5066f3b6-81d5-4737-b701-4a193a10c815",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluation(model, dataloader):\n",
    "    with torch.no_grad():\n",
    "        model.eval()\n",
    "        criterion = nn.CrossEntropyLoss()\n",
    "        val_loss, val_accuracy = 0.0, 0.0\n",
    "        \n",
    "        for input_ids, attention_mask, labels in dataloader:\n",
    "            outputs = model(\n",
    "                input_ids = input_ids,\n",
    "                attention_mask = attention_mask,\n",
    "                labels = labels\n",
    "            )\n",
    "            logits = outputs.logits\n",
    "            \n",
    "            loss = criterion(logits, labels)\n",
    "            logtis = logits.detach().cpu().numpy()\n",
    "            labels_ids = labels.to('cpu').numpy()\n",
    "            accuracy = calc_accuracy(logits, labels_ids)\n",
    "            \n",
    "            val_loss += loss\n",
    "            val_accuracy += accuracy\n",
    "            \n",
    "        val_loss = val_loss/len(dataloader)\n",
    "        val_accuracy = val_accuracy / len(dataloader)\n",
    "        return val_loss, val_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "aeb42280-3119-4ed3-87b8-783eec71f74f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\dohyeong\\anaconda3\\lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py:439: UserWarning: 1Torch was not compiled with flash attention. (Triggered internally at C:\\cb\\pytorch_1000000000000\\work\\aten\\src\\ATen\\native\\transformers\\cuda\\sdp_utils.cpp:555.)\n",
      "  attn_output = torch.nn.functional.scaled_dot_product_attention(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 train loss: 0.6460 val loss: 0.6463 val_acc: 0.6512\n",
      "Epoch: 2 train loss: 0.6371 val loss: 0.6466 val_acc: 0.6512\n",
      "Epoch: 3 train loss: 0.6322 val loss: 0.6500 val_acc: 0.6512\n",
      "Epoch: 4 train loss: 0.6122 val loss: 0.6508 val_acc: 0.6472\n",
      "Epoch: 5 train loss: 0.5832 val loss: 0.7463 val_acc: 0.6089\n"
     ]
    }
   ],
   "source": [
    "best_loss = 10000\n",
    "for epoch in range(epochs):\n",
    "    train_loss = train(model, optimizer, train_dataloader)\n",
    "    val_loss, val_accuracy = evaluation(model, valid_dataloader)\n",
    "    print(f'Epoch: {epoch+1} train loss: {train_loss:.4f} val loss: {val_loss:.4f} val_acc: {val_accuracy:.4f}')\n",
    "    \n",
    "    if val_loss < best_loss:\n",
    "        best_loss = val_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "aa26b122-4a59-4a39-855e-7fb3446ca3a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loss, test_score = evaluation(model, test_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "df277cef-f931-4c30-91a2-3efa326fa8e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.7079, device='cuda:0')"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "c678058b-21af-4938-9e25-197ce641c691",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6491935483870968"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdb685b5-3767-450c-a559-0a2f49d6e9d5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93a41151-dd4a-48da-82ec-1f852b4b2aee",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ff00f63-056f-441f-b51a-dabe0f3e6b2b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
